{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BooBoa/Stable_diffusion-dreamlikediffusion/blob/main/Stable_Diffusion_2_1_Dreamlike_art_dreamlike_diffusion_1_0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aIrgth7sqFML",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Run This Cell first: will install all requirements.\n",
        "!pip install \"ipywidgets>=7,<8\"\n",
        "%pip install --quiet --upgrade diffusers transformers scipy mediapy accelerate ftfy spacy\n",
        "import subprocess\n",
        "# The xformers package is mandatory to be able to create several 768x768 images.\n",
        "github_url = \"https://github.com/brian6091/xformers-wheels\"\n",
        "xformer_id = \"0.0.15.dev0+4c06c79\"\n",
        "xformers_wheels = f\"xformers-{xformer_id}.d20221205-cp38-cp38-linux_x86_64.whl\"\n",
        "# Install xformers using pre-compiled Python wheels\n",
        "%pip install -q {github_url}/releases/download/{xformer_id}/{xformers_wheels}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "va1InKAdvpEL",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "\n",
        "#@title Dreamlike Diffusion\n",
        "import torch\n",
        "from torch import autocast\n",
        "from diffusers import StableDiffusionPipeline, DDIMScheduler\n",
        "from IPython.display import display\n",
        "from numpy import int16\n",
        "\n",
        "model_id = \"dreamlike-art/dreamlike-diffusion-1.0\"           \n",
        "scheduler = DDIMScheduler(beta_start=0.00085,\n",
        "                          beta_end=0.012,\n",
        "                          beta_schedule=\"scaled_linear\",\n",
        "                          clip_sample=False,\n",
        "                          set_alpha_to_one=False)\n",
        "\n",
        "pipe = StableDiffusionPipeline.from_pretrained(model_id,\n",
        "                                               scheduler=scheduler,\n",
        "                                               safety_checker=None,\n",
        "                                               torch_dtype=torch.float16).to(\"cuda\")\n",
        "\n",
        "pipe.enable_attention_slicing()\n",
        "pipe.enable_xformers_memory_efficient_attention()\n",
        "\n",
        "\n",
        "g_cuda = None\n",
        "g_cuda = torch.Generator(device='cuda')\n",
        "seed = 65743829 #@param {type:\"number\"}\n",
        "g_cuda.manual_seed(seed)\n",
        "prompt = \"dreamlikeart apocalyptic person and there pet, a breathtaking digital illustration, beautiful anime characters, wearing hazmat suits, post apocalytic on background\" #@param {type:\"string\"}\n",
        "negative_prompt = \"bright eyes, duplicate, morbid, mutilated, out of frame, extra fingers, mutated hands, poorly drawn hands, poorly drawn face, mutation, blurry, deformed, ugly, bad anatomy, bad proportions, extra limbs, cloned face, gross proportions, malformed limbs, missing arms, missing legs, extra arms, extra legs, fused fingers, too many fingers, long neck\" #@param {type:\"string\"}\n",
        "num_samples = 100 #@param {type:\"slider\", min:1, max:100, step:1}\n",
        "guidance_scale = 9.5 #@param {type:\"slider\", min:1, max:20, step:0.1}\n",
        "num_inference_steps = 30 #@param {type:\"slider\", min:1, max:500, step:1}\n",
        "height = 768 #@param {type:\"number\"}\n",
        "width = 768 #@param {type:\"number\"}\n",
        "\n",
        "for i in range(num_samples):\n",
        "  with autocast(\"cuda\"), torch.inference_mode():\n",
        "      images = pipe(\n",
        "          prompt,\n",
        "          height=height,\n",
        "          width=width,\n",
        "          negative_prompt=negative_prompt,\n",
        "          num_inference_steps=num_inference_steps,\n",
        "          guidance_scale=guidance_scale,\n",
        "          generator=g_cuda\n",
        "      ).images\n",
        "  seed += 100\n",
        "\n",
        "  for img in images:\n",
        "      img.save(f\"Seed_{seed}.png\")  \n",
        "      display(img)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Stable-diffusion-2-1\n",
        "from diffusers import StableDiffusionPipeline, DPMSolverMultistepScheduler\n",
        "import torch\n",
        "from torch import autocast\n",
        "from IPython.display import display\n",
        "\n",
        "\n",
        "# model_id = 'stabilityai/stable-diffusion-2'\n",
        "model_id = 'stabilityai/stable-diffusion-2-1'\n",
        "\n",
        "scheduler = DPMSolverMultistepScheduler.from_pretrained(model_id, subfolder=\"scheduler\")\n",
        "\n",
        "pipe = StableDiffusionPipeline.from_pretrained(\n",
        "    model_id,\n",
        "    revision=\"fp16\",\n",
        "    torch_dtype=torch.float16,\n",
        "    scheduler=scheduler\n",
        ").to(\"cuda\")\n",
        "\n",
        "pipe.enable_attention_slicing()\n",
        "pipe.enable_xformers_memory_efficient_attention()\n",
        "\n",
        "g_cuda = None\n",
        "g_cuda = torch.Generator(device=\"cuda\")\n",
        "seed = 64738 #@param{type:\"number\"}\n",
        "g_cuda.manual_seed(seed)\n",
        "prompt = \"a post apocalyptic girl, a breathtaking digital illustration, beautiful anime characters, wearing hazmat suits, post apocalytic on background, \"#@param{type:\"string\"}\n",
        "neg_prompt = \" low res, duplicate, morbid, mutilated, out of frame, extra fingers, mutated hands, poorly drawn hands, poorly drawn face, mutation, blurry, deformed, ugly, bad anatomy, bad proportions, extra limbs, cloned face, gross proportions, malformed limbs, missing arms, missing legs, extra arms, extra legs, fused fingers, too many fingers, long neck\"#@param{type:\"string\"}\n",
        "num_samples = 10 #@param{type:\"slider\", min:1, max:100, steps:1}\n",
        "steps = 35 #@param{type:\"slider\", min:10, max:500, steps:1}\n",
        "guidance_scale = 9.5 #@param{type:\"slider\", min:1, max:20, step:0.1}\n",
        "width = 768 #@param{type:\"number\"}\n",
        "height = 768 #@param{type:\"number\"}\n",
        "\n",
        "for i in range(num_samples):\n",
        "    with autocast(\"cuda\"):\n",
        "        images = pipe(\n",
        "            prompt = prompt,\n",
        "            negative_prompt = neg_prompt,\n",
        "            num_inference_steps = steps,\n",
        "            guidance_scale = guidance_scale,\n",
        "            width = width,\n",
        "            height = height,\n",
        "            generator = g_cuda\n",
        "        ).images\n",
        "\n",
        "    seed += 100\n",
        "\n",
        "    for img in images:\n",
        "        img.save(f\"seed_{seed}.png\")\n",
        "        display(img)"
      ],
      "metadata": {
        "id": "B29FmAWwHqib",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}